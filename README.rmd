---
title: "User guide for package m6ALogisticModel"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Installation
Currently, you could install this package using this command.
```{r,eval=FALSE}
devtools::install_github("ZhenWei10/m6ALogisticModel")
```

<hr/>

## Motivation
The major reasons for me to create this package is to:

1. Dealing with **confounding genomic features** that are common in RNA genomics.

2. Reduce the traditional work load for creating and screening the highly explanatory RNA features one by one, while unable to account the dependencies between those features.

3. Provide a template for the linear modeling on the relationship between **belonging (dummy), relative position, and length** for a given feature of transcript region. The previous researches suggest that these 3 different properties of a region are important predictors for the behaviours of m6A in different biological context.

**Logistic regression modeling** seems to be a reasonable computational technique here, since it can efficiently quantify the scientific and statistical significance for all the features, while adjust their dependencies on each others. The logistic regression is coupled with bayesian model selection method on genaralized linear model for reasons of reduced model qualities and inferential power in the presence of large amount of highly correlated features. 

The funcions for transcript feature annotation and the logistic modeling are included in this package; while at the same time, users can introduce more genomic features defined by them self using GRanges object. Effective visualization for comparation between multiple selected models are also implemented in this package.


<hr/>


## A case study with this package.

To demonstrate the application of this package, I provide a case analysis on finding the transcriptomic features that can predict the evolutionary conservation of m6A locations. The m6A locations used were reported by [RMBase2](http://rna.sysu.edu.cn/rmbase/), and the genomic conservation scores used are extracted from the bioconductor packages [phastCons100way.UCSC.hg19](http://www.bioconductor.org/packages/release/data/annotation/html/phastCons100way.UCSC.hg19.html) and [fitCons.UCSC.hg19](http://www.bioconductor.org/packages/release/data/annotation/html/fitCons.UCSC.hg19.html).

```{r, cache = TRUE,message=FALSE,warning=FALSE}
library(m6ALogisticModel)
library(fitCons.UCSC.hg19)
library(phastCons100way.UCSC.hg19)
```
The m6A location information is stored within data `SE_example` of the package `m6ALogisticMode`.

The rowRanges contains the conserved m6A sites reported by RMBase2 between hg19 and mm10.

```{r, cache = TRUE,message=FALSE,warning=FALSE}
library(SummarizedExperiment)
RMBase2_hg19_gr <- rowRanges( SE_example )
```

<hr/>

###Define targets (response variables)

The PhastCons scores and fitCons scores of the m6A underlying sequences are extracted, each with bins of 1bp, 5bp, and 51bp.

```{r, cache = TRUE,message=FALSE,warning=FALSE}
library(dplyr)

Flank_sizes = c(0,2,25)

PhastCons_matrix <- lapply(Flank_sizes, 
      function(flank_size) scores(phastCons100way.UCSC.hg19,RMBase2_hg19_gr + flank_size)$scores
        ) %>% Reduce(cbind,.)

FitCons_matrix <- lapply(Flank_sizes, 
      function(flank_size) scores(fitCons.UCSC.hg19,RMBase2_hg19_gr + flank_size)$scores
        ) %>% Reduce(cbind,.)

ConsScore_matrix <- cbind(PhastCons_matrix,FitCons_matrix)

colnames(ConsScore_matrix) = paste0( rep(c("PastCons","FitCons"),
                                           each = length(Flank_sizes)),"_",
                                     rep((Flank_sizes)*2+1,2) , "bp")
```

Visualize the distribution of the scores, and choose the cut off values to convert the scores into binary variables.

```{r, cache = TRUE,message=FALSE,warning=FALSE,fig.width=9,fig.align='center'}
Plot_df <- reshape2::melt(ConsScore_matrix)
Plot_df$X_intercept = NA
cut_offs <- c(.9,.9,.8,.7,.7,.7)
for (i in 1:(2*length(Flank_sizes))){
Plot_df$X_intercept[Plot_df$Var2 == colnames(ConsScore_matrix)[i]] <- cut_offs[i]
}
library(ggplot2)
ggplot(Plot_df) + geom_histogram(aes(x = value),fill = "grey") + facet_wrap(~Var2, nrow = 2, scales = "free_y") + theme_classic() + geom_vline(aes(xintercept = X_intercept),colour = "blue")
```

```{r,cache=T}
#Convert the matrix with only entries of 0, 1, and NA using the cut_off defined above
for(i in 1:6) {
ConsScore_matrix[,i] <- as.numeric(ConsScore_matrix[,i] > cut_offs[i])
}

#Calculate proportions of positive instances in Target
for(i in 1:6) {
 cat( paste0(colnames(ConsScore_matrix)[i],": ", round( mean( ConsScore_matrix[,i],na.rm = T) ,3) , "\n"))
}
```


The targets still face the issue of not having balanced classes, but for now, we will just omit it and plug it into our logistic regression functions.

<hr/>

###Generate features (predictors)

The hg19 `TxDb` and `BSgenome` are loaded for the purpose of extracting the transcriptomic features.

```{r, cache = TRUE,warning=FALSE}
library(TxDb.Hsapiens.UCSC.hg19.knownGene)
library(BSgenome.Hsapiens.UCSC.hg19)
SE <- SummarizedExperiment(ConsScore_matrix)
rowRanges(SE) = RMBase2_hg19_gr

Feature_List_hg19 = list(
HNRNPC_eCLIP = eCLIP_HNRNPC_gr,
YTHDC1_TREW = YTHDC1_TREW_gr,
YTHDF1_TREW = YTHDF1_TREW_gr,
YTHDF2_TREW = YTHDF2_TREW_gr,
miR_targeted_genes = miR_targeted_genes_grl,
TargetScan = TargetScan_hg19_gr,
Verified_miRtargets = verified_targets_gr
)

SE <- m6ALogisticModel::predictors.annot(se = SE,
                                   txdb = TxDb.Hsapiens.UCSC.hg19.knownGene,
                                   bsgnm = BSgenome.Hsapiens.UCSC.hg19,
                                   struct_hybridize = Struc_hg19,
                                   feature_lst = Feature_List_hg19,
                                   HK_genes_list = HK_hg19_eids)
```

49 Transcriptomic features on hg19 are automatically attached by the command and data defined in `m6ALogisticModel`.

<hr/>

###Model selection and inference

- Run the following commands, you will find results after some running times.
- You could make this process much more efficient with reduced `MCMC_interations` number and reduced instance numbers in your matrix.

```{r,cache = T,eval=FALSE}
Group_list <- group_list_default[names(group_list_default) != "Evolution"]

m6ALogisticModel::logistic.modeling(SE,
                                    save_dir = "Conservation_scores",
                                    group_list = Group_list,
                                    MCMC_iterations = 100000)
```


<hr/>

```{r}
sessionInfo()
```

